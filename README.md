# TelecomX_BR_parte2
Projeto de anÃ¡lise de dados e Machine Learning One Oracle-Alura-ClearSale

TelecomX_BR_parte2 â€” PrevisÃ£o de EvasÃ£o de Clientes
ğŸ“Œ DescriÃ§Ã£o do Projeto
Este projeto faz parte do Challenge Telecom X â€“ Parte 2 e tem como objetivo desenvolver modelos preditivos capazes de prever quais clientes tÃªm maior chance de cancelar seus serviÃ§os.
A anÃ¡lise permite que a empresa antecipe aÃ§Ãµes para reduzir a evasÃ£o (churn), otimizando estratÃ©gias de retenÃ§Ã£o.

ğŸ¯ Objetivos
PreparaÃ§Ã£o dos dados para modelagem:
EliminaÃ§Ã£o de colunas irrelevantes (ex.: IDs).
CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas (One-Hot Encoding).
AnÃ¡lise de balanceamento das classes.
AplicaÃ§Ã£o opcional de tÃ©cnicas de balanceamento (SMOTE, oversampling, undersampling).
NormalizaÃ§Ã£o/PadrÃ£o de dados quando necessÃ¡rio.
AnÃ¡lise exploratÃ³ria e seleÃ§Ã£o de variÃ¡veis:
Matriz de correlaÃ§Ã£o para variÃ¡veis numÃ©ricas.
IdentificaÃ§Ã£o de variÃ¡veis mais correlacionadas com a evasÃ£o.
VisualizaÃ§Ãµes: Boxplots, Scatter Plots.
Treinamento e avaliaÃ§Ã£o de modelos:
SeparaÃ§Ã£o dos dados em treino e teste.
Teste de pelo menos dois modelos:
Um sensÃ­vel Ã  escala (ex.: RegressÃ£o LogÃ­stica, KNN).
Um nÃ£o sensÃ­vel Ã  escala (ex.: Ãrvore de DecisÃ£o, Random Forest, XGBoost).
AvaliaÃ§Ã£o com mÃ©tricas:
AcurÃ¡cia
PrecisÃ£o
Recall
F1-score
Matriz de confusÃ£o
ComparaÃ§Ã£o de desempenho e anÃ¡lise de overfitting/underfitting.

ConclusÃ£o estratÃ©gica:
Principais fatores que influenciam a evasÃ£o.
Modelo mais adequado para o cenÃ¡rio.

ğŸ“‚ Estrutura do Projeto
TelecomX_BR_parte2/
â”‚-- data/
â”‚   â”œâ”€â”€ df_limpo.csv              # Base de dados tratada na Parte 1
â”‚-- notebooks/
â”‚   â”œâ”€â”€ TelecomX_BR_parte2.ipynb  # Notebook principal com todo o pipeline
â”‚-- results/
â”‚   â”œâ”€â”€ matriz_confusao.png
â”‚   â”œâ”€â”€ comparativo_f1.png
â”‚-- README.md

Pipeline de Modelagem
ImportaÃ§Ã£o dos dados tratados da Parte 1.
PrÃ©-processamento:
RemoÃ§Ã£o de colunas irrelevantes.
Encoding de variÃ¡veis categÃ³ricas.
Balanceamento das classes (SMOTE opcional).
NormalizaÃ§Ã£o quando necessÃ¡rio.
AnÃ¡lise exploratÃ³ria e seleÃ§Ã£o de variÃ¡veis.
Treinamento de modelos:
Modelos baseados em distÃ¢ncia (com normalizaÃ§Ã£o).
Modelos baseados em Ã¡rvore (sem necessidade de normalizaÃ§Ã£o).
AvaliaÃ§Ã£o com mÃ©tricas e escolha do melhor modelo via F1-score.

ConclusÃµes estratÃ©gicas.
ğŸ“ˆ Resultados Obtidos
Modelo escolhido:
ğŸ”¹ XGBoost (tuned) â€” F1-score: 0.6268
Matriz de ConfusÃ£o â€” InterpretaÃ§Ã£o:
Boa taxa de acerto para a classe "NÃ£o" (clientes que nÃ£o cancelaram).
Necessidade de melhorar o Recall da classe "Sim" (clientes que cancelaram), pois ainda existem falsos negativos relevantes.
ComparaÃ§Ã£o com outros modelos:
Random Forest apresentou desempenho prÃ³ximo, mas o XGBoost obteve melhor equilÃ­brio entre PrecisÃ£o e Recall.

ğŸ§  ConclusÃµes EstratÃ©gicas
Principais fatores de evasÃ£o incluem tempo de contrato, total gasto e tipo de serviÃ§o contratado.
XGBoost apresentou:
Melhor equilÃ­brio entre precisÃ£o e recall.
Maior F1-score no conjunto de teste.
Potencial para otimizaÃ§Ãµes adicionais (ajuste de hiperparÃ¢metros, feature engineering avanÃ§ado).

PrÃ³ximos passos:
Ajustar o Recall da classe positiva.
Criar alertas proativos para clientes com alto risco de churn.

ğŸ“Œ Tecnologias Utilizadas
Python (Pandas, NumPy, Scikit-learn, XGBoost, Imbalanced-learn)
VisualizaÃ§Ã£o (Matplotlib, Seaborn)
Google Colab para desenvolvimento
GitHub para versionamento e publicaÃ§Ã£o

ğŸ“¬ Autor
Desenvolvido por Vanessa Santos como parte do desafio Telecom X.
